{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35f6090-2f61-41b6-aabc-a8d80ad518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import *\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import glob\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "994b1e27-c89a-4ee9-85dc-292eddc4f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialze the estimators\n",
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "# clf2 = SVC(kernel='sigmoid',probability=True, random_state=42)\n",
    "clf3 = LogisticRegression(random_state=42)\n",
    "clf4 = DecisionTreeClassifier(random_state=42)\n",
    "clf5 = KNeighborsClassifier()\n",
    "clf6 = MultinomialNB()\n",
    "# clf7 = GradientBoostingClassifier(random_state=42)\n",
    "clf8 = MLPClassifier(max_iter=2000,random_state=42)\n",
    "clf9 = SVC(kernel='poly',probability=True, random_state=42)\n",
    "# clf10 = SVC(kernel='rbf',probability=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89c51e29-4ee9-44b3-a0e1-0743a99e778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(object):\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = cols\n",
    "    def transform(self, X):\n",
    "        return X[:,self.cols]\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def get_params(self,deep=True):\n",
    "        return {\"cols\" : self.cols}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2da986-2722-4e42-a24e-3a2b713f5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiaze the hyperparameters for each dictionary\n",
    "param1 = {}\n",
    "param1['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param1['classifier__n_estimators'] = [10, 20, 30, 40]\n",
    "param1['classifier__max_depth'] = [2, 3, 4]\n",
    "param1['classifier__class_weight'] = [None, 'balanced']\n",
    "# param1['classifier'] = [clf1]\n",
    "\n",
    "param2 = {}\n",
    "param2['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param2['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "# param2['Classifier__kernel'] = [ 'linear']\n",
    "param2['classifier__class_weight'] = [None, 'balanced']\n",
    "param2['classifier__degree'] = [2,3]\n",
    "# param2['classifier'] = [clf2]\n",
    "\n",
    "param3 = {}\n",
    "param3['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param3['classifier__C'] = [10**-2, 10**-1, 10**0, 10**1, 10**2]\n",
    "param3['classifier__penalty'] = ['l1', 'l2']\n",
    "param3['classifier__class_weight'] = [None, 'balanced']\n",
    "# param3['classifier'] = [clf3]\n",
    "\n",
    "param4 = {}\n",
    "param4['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,4)], [])\n",
    "param4['classifier__max_depth'] = [2,3,4,None]\n",
    "param4['classifier__min_samples_split'] = [2,3,4]\n",
    "param4['classifier__class_weight'] = [None, 'balanced']\n",
    "# param4['classifier'] = [clf4]\n",
    "\n",
    "param5 = {}\n",
    "param5['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param5['classifier__n_neighbors'] = [2,3,4,5]\n",
    "# param5['classifier'] = [clf5]\n",
    "\n",
    "param6 = {}\n",
    "param6['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param6['classifier__alpha'] = [10**0, 10**1, 10**2]\n",
    "# param6['classifier'] = [clf6]\n",
    "\n",
    "param7 = {}\n",
    "param7['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param7['classifier__n_estimators'] = [10, 20, 30, 40]\n",
    "param7['classifier__max_depth'] = [2, 3, 4]\n",
    "# param7['classifier'] = [clf7]\n",
    "\n",
    "param8 = {}\n",
    "param8['feat_select__cols'] = sum([list(combinations(np.arange(0,4,1), i)) for i in range(1,5)], [])\n",
    "param8['classifier__hidden_layer_sizes'] = [(10),(10,10),(10,10,10)]\n",
    "param8['classifier__solver'] = ['adam', 'sgd']\n",
    "param8['classifier__alpha'] = [0.0001, 0.0005,0.001,0.005,0.01,0.05]    \n",
    "# param8['classifier'] = [clf8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f8377b0d-68ef-46cc-9309-892ac57acbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf1)])\n",
    "# pipeline2 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf2)])\n",
    "pipeline3 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf3)])\n",
    "pipeline4 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf4)])\n",
    "pipeline5 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf5)])\n",
    "pipeline6 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf6)])\n",
    "# pipeline7 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf7)])\n",
    "pipeline8 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf8)])\n",
    "pipeline9 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf9)])\n",
    "# pipeline10 = Pipeline([('feat_select',ColumnExtractor()),('classifier', clf10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5eef0bf1-1679-4fee-9e16-990691c3aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootPath = \"./\"\n",
    "X_train = pd.read_csv(rootPath + \"X_train_tenengrad.csv\")\n",
    "X_test = pd.read_csv(rootPath + \"X_test_tenengrad.csv\")\n",
    "y_train = pd.read_csv(rootPath + \"y_train_tenengrad.csv\").values.reshape(-1)\n",
    "y_test = pd.read_csv(rootPath + \"y_test_tenengrad.csv\").values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "71d68ca3-e271-47e6-88e3-0d2ede7cae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.zeros(len(y_train) + len(y_test))\n",
    "indices[:len(y_train)] = -1\n",
    "Data_X = np.vstack([X_train,X_test])\n",
    "Data_Y = np.hstack([y_train,y_test])\n",
    "\n",
    "ps = PredefinedSplit(indices)\n",
    "score = { \"Accuracy\":\"balanced_accuracy\" ,\"Recall\":\"recall_weighted\",\"Precision\":\"precision_weighted\",\"F1_Score\":\"f1_weighted\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f08c52e3-7708-4bad-a261-bbbdd2194ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1 = GridSearchCV(pipeline1, n_jobs=-1, param_grid=[param1],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "# grid2 = GridSearchCV(pipeline2, n_jobs=-1, param_grid=[param2],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "grid3 = GridSearchCV(pipeline3, n_jobs=-1, param_grid=[param3],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "grid4 = GridSearchCV(pipeline4, n_jobs=-1, param_grid=[param4],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "grid5 = GridSearchCV(pipeline5, n_jobs=-1, param_grid=[param5],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "grid6 = GridSearchCV(pipeline6, n_jobs=-1, param_grid=[param6],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "# grid7 = GridSearchCV(pipeline7, n_jobs=-1, param_grid=[param7],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "grid8 = GridSearchCV(pipeline8, n_jobs=-1, param_grid=[param8],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "grid9 = GridSearchCV(pipeline9, n_jobs=-1, param_grid=[param2],scoring=score,refit=\"F1_Score\",cv=ps)\n",
    "# grid10 = GridSearchCV(pipeline10, n_jobs=-1, param_grid=[param2],scoring=score,refit=\"F1_Score\",cv=ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0f85649-e85b-4410-8f74-403ad6a64727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grids = [grid1,grid3,grid4,grid5,grid6,grid8,grid9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1ce542b8-60ba-4d2f-a92b-a182f791e06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Done\n",
      "Yes Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "150 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "150 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.45714286 0.45714286 0.42857143 0.45714286 0.28571429\n",
      " 0.37142857 0.22857143 0.2        0.22857143 0.34285714 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.45714286 0.45714286 0.42857143 0.45714286 0.28571429\n",
      " 0.37142857 0.22857143 0.2        0.22857143 0.34285714 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.42857143 0.45714286 0.42857143 0.45714286 0.34285714\n",
      " 0.4        0.22857143 0.2        0.2        0.25714286 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.42857143 0.45714286 0.42857143 0.45714286 0.34285714\n",
      " 0.4        0.22857143 0.2        0.2        0.25714286 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.45714286 0.45714286 0.4        0.34285714 0.4\n",
      " 0.42857143 0.2        0.25714286 0.2        0.28571429 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.45714286 0.45714286 0.4        0.34285714 0.4\n",
      " 0.42857143 0.2        0.25714286 0.2        0.28571429 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.2        0.42857143 0.37142857 0.42857143 0.48571429\n",
      " 0.31428571 0.2        0.17142857 0.22857143 0.28571429 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.2        0.42857143 0.37142857 0.42857143 0.48571429\n",
      " 0.31428571 0.2        0.17142857 0.22857143 0.28571429 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.45714286 0.34285714 0.37142857 0.37142857 0.4\n",
      " 0.42857143 0.2        0.25714286 0.2        0.25714286 0.2\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.31428571 0.42857143 0.4\n",
      " 0.31428571 0.45714286 0.34285714 0.37142857 0.37142857 0.4\n",
      " 0.42857143 0.2        0.25714286 0.2        0.25714286 0.2       ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.45040293 0.45214286 0.54725275 0.55833333 0.36439394\n",
      " 0.38692641 0.0816092  0.06837607 0.28761905 0.39929825 0.0780303\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.45040293 0.45214286 0.54725275 0.55833333 0.36439394\n",
      " 0.38692641 0.0816092  0.06837607 0.28761905 0.39929825 0.0780303\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.35337662 0.45214286 0.41333333 0.54945055 0.27904762\n",
      " 0.43222222 0.09059829 0.06818182 0.04516129 0.25873016 0.0780303\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.35337662 0.45214286 0.41333333 0.54945055 0.27904762\n",
      " 0.43222222 0.09059829 0.06818182 0.04516129 0.25873016 0.0780303\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.54242424 0.45333333 0.32692308 0.28661616 0.43333333\n",
      " 0.39980519 0.0780303  0.28933333 0.08550725 0.32596491 0.04375\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.54242424 0.45333333 0.32692308 0.28661616 0.43333333\n",
      " 0.39980519 0.0780303  0.28933333 0.08550725 0.32596491 0.04375\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.04       0.38095238 0.37333333 0.44666667 0.48333333\n",
      " 0.25050505 0.08       0.26333333 0.28311688 0.22333333 0.06944444\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.04       0.38095238 0.37333333 0.44666667 0.48333333\n",
      " 0.25050505 0.08       0.26333333 0.28311688 0.22333333 0.06944444\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.46242424 0.41846154 0.37619048 0.35142857 0.375\n",
      " 0.42444444 0.07142857 0.31494253 0.073      0.25929825 0.0780303\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.23611111 0.34935897 0.33909091\n",
      " 0.28       0.46242424 0.41846154 0.37619048 0.35142857 0.375\n",
      " 0.42444444 0.07142857 0.31494253 0.073      0.25929825 0.0780303 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.43142857 0.44335429 0.40608862 0.43526316 0.27944444\n",
      " 0.35922587 0.10854701 0.09772727 0.16848739 0.32034188 0.10896057\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.43142857 0.44335429 0.40608862 0.43526316 0.27944444\n",
      " 0.35922587 0.10854701 0.09772727 0.16848739 0.32034188 0.10896057\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.37744361 0.44335429 0.39469917 0.42611722 0.30630252\n",
      " 0.36474028 0.12272727 0.09964158 0.07368421 0.20587302 0.10896057\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.37744361 0.44335429 0.39469917 0.42611722 0.30630252\n",
      " 0.36474028 0.12272727 0.09964158 0.07368421 0.20587302 0.10896057\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.44069848 0.4427499  0.34365109 0.30525253 0.36947118\n",
      " 0.40207792 0.10896057 0.16826923 0.11076923 0.24842634 0.07179487\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.44069848 0.4427499  0.34365109 0.30525253 0.36947118\n",
      " 0.40207792 0.10896057 0.16826923 0.11076923 0.24842634 0.07179487\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.06666667 0.39657316 0.36699849 0.43110106 0.45601276\n",
      " 0.26309942 0.10955882 0.13654971 0.16133005 0.23587001 0.0972549\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.06666667 0.39657316 0.36699849 0.43110106 0.45601276\n",
      " 0.26309942 0.10955882 0.13654971 0.16133005 0.23587001 0.0972549\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.44259907 0.29666667 0.3717033  0.3385536  0.36939271\n",
      " 0.40684492 0.09714286 0.16777778 0.10166667 0.20842634 0.10896057\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.25       0.36666667 0.36\n",
      " 0.27986663 0.44259907 0.29666667 0.3717033  0.3385536  0.36939271\n",
      " 0.40684492 0.09714286 0.16777778 0.10166667 0.20842634 0.10896057]\n",
      "  warnings.warn(\n",
      "C:\\Users\\ronakdediya\\anaconda33\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes Done\n",
      "Yes Done\n",
      "Yes Done\n",
      "Yes Done\n",
      "Yes Done\n"
     ]
    }
   ],
   "source": [
    "for pipe in grids:\n",
    "    print(\"Yes Done\")\n",
    "    pipe.fit(Data_X,Data_Y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ccb5756-436b-4f6c-9c28-581d50dcaff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('feat_select',\n",
      "                 <__main__.ColumnExtractor object at 0x000001AAD1CD82B0>),\n",
      "                ('classifier',\n",
      "                 SVC(C=0.1, kernel='poly', probability=True, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "grid = grids[6]\n",
    "print(grid.best_estimator_)\n",
    "# print(pd.DataFrame(grid.cv_results_).iloc[grid.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a9dddba-2d70-4703-9900-b86bd2665815",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grid.cv_results_).drop(columns=[\"mean_fit_time\",\"std_fit_time\",\"mean_score_time\",\"std_score_time\",\"params\",\n",
    "                                             \"mean_test_Accuracy\",\"std_test_Accuracy\",\"rank_test_Accuracy\",\n",
    "                                            \"mean_test_Recall\",\"std_test_Recall\",\"rank_test_Recall\",\n",
    "                                            \"mean_test_Precision\",\"std_test_Precision\",\"rank_test_Precision\",\n",
    "                                            \"mean_test_F1_Score\",\"std_test_F1_Score\",\"rank_test_F1_Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ac7ce343-61ec-404c-ad5e-7de603dd97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sum\"] = df[\"split0_test_Accuracy\"] + df[\"split0_test_Recall\"] + df[\"split0_test_Precision\"] + df[\"split0_test_F1_Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "40f8c948-0199-47c1-8133-202b68885f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__class_weight</th>\n",
       "      <th>param_classifier__degree</th>\n",
       "      <th>param_feat_select__cols</th>\n",
       "      <th>split0_test_Accuracy</th>\n",
       "      <th>split0_test_Recall</th>\n",
       "      <th>split0_test_Precision</th>\n",
       "      <th>split0_test_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 2, 3)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.418022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.416752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 3)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.425556</td>\n",
       "      <td>0.409697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.418022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 2, 3)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.418022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.418022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 1, 3)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.425556</td>\n",
       "      <td>0.409697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 2, 3)</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.416752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1, 2)</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.412381</td>\n",
       "      <td>0.387253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>2</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.391270</td>\n",
       "      <td>0.388394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_classifier__C param_classifier__class_weight  \\\n",
       "149                   1                           None   \n",
       "178                   1                       balanced   \n",
       "296                 100                       balanced   \n",
       "115                 0.1                       balanced   \n",
       "179                   1                       balanced   \n",
       "85                  0.1                           None   \n",
       "266                 100                           None   \n",
       "148                   1                           None   \n",
       "100                 0.1                       balanced   \n",
       "274                 100                       balanced   \n",
       "\n",
       "    param_classifier__degree param_feat_select__cols  split0_test_Accuracy  \\\n",
       "149                        3            (0, 1, 2, 3)              0.457143   \n",
       "178                        3               (1, 2, 3)              0.457143   \n",
       "296                        3               (0, 1, 3)              0.457143   \n",
       "115                        3               (0, 1, 2)              0.457143   \n",
       "179                        3            (0, 1, 2, 3)              0.457143   \n",
       "85                         3               (0, 1, 2)              0.457143   \n",
       "266                        3               (0, 1, 3)              0.457143   \n",
       "148                        3               (1, 2, 3)              0.457143   \n",
       "100                        2               (0, 1, 2)              0.428571   \n",
       "274                        2                  (0, 1)              0.428571   \n",
       "\n",
       "     split0_test_Recall  split0_test_Precision  split0_test_F1_Score  \n",
       "149            0.457143               0.445714              0.418022  \n",
       "178            0.457143               0.468333              0.416752  \n",
       "296            0.457143               0.425556              0.409697  \n",
       "115            0.457143               0.445714              0.418022  \n",
       "179            0.457143               0.445714              0.418022  \n",
       "85             0.457143               0.445714              0.418022  \n",
       "266            0.457143               0.425556              0.409697  \n",
       "148            0.457143               0.468333              0.416752  \n",
       "100            0.428571               0.412381              0.387253  \n",
       "274            0.428571               0.391270              0.388394  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(\"split0_test_Accuracy\")[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57f10a9-32dc-478b-b0f1-91876c3c187a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [92.95910811424255]\n",
       "1      [82.2305908203125]\n",
       "2     [82.43215727806091]\n",
       "3     [80.79285311698914]\n",
       "4      [80.9026141166687]\n",
       "             ...         \n",
       "85    [78.49931454658508]\n",
       "86     [77.7010612487793]\n",
       "87    [77.35790419578552]\n",
       "88    [76.98056769371033]\n",
       "89    [76.88145112991333]\n",
       "Name: 0, Length: 90, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"time_hwt.csv\").iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f1bed-a0a1-4792-92b3-ca561cb5aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b6a124-5cde-49b1-bf9a-c22abb78e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "95sec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
