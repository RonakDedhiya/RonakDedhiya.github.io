{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a7f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, Activation, Dense, Lambda, Input, MaxPooling2D, Dropout, Flatten, Reshape, UpSampling2D, Concatenate\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import tensorboard_v2\n",
    "\n",
    "import keras\n",
    "\n",
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "\n",
    "# Augment data with A-Z letter images from sachinpatel21\n",
    "\n",
    "letters = np.array(pd.read_csv('A_Z Handwritten Data.csv', header=None))\n",
    "sample = np.random.random(len(letters)) < 1.0 / 7\n",
    "x_train = np.concatenate((x_train, letters[np.logical_not(sample), 1:]))\n",
    "x_test = np.concatenate((x_test, letters[sample, 1:]))\n",
    "y_train = np.concatenate((y_train, letters[np.logical_not(sample), 0] + 10))\n",
    "y_test = np.concatenate((y_test, letters[sample, 0] + 10))\n",
    "\n",
    "letters = np.array(pd.read_csv('A_Z Handwritten Data.csv', header=None))\n",
    "skf = StratifiedKFold(n_splits=2,shuffle=True,random_state=42)\n",
    "a,b = list(skf.split(letters,letters[:,1]))[0]\n",
    "x_train = np.concatenate((x_train, letters[a, 1:]))\n",
    "x_test = np.concatenate((x_test, letters[b, 1:]))\n",
    "y_train = np.concatenate((y_train, letters[a, 0] + 10))\n",
    "y_test = np.concatenate((y_test, letters[b, 0] + 10))\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 36)\n",
    "y_test = to_categorical(y_test, 36)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample eps = N(0,I)\n",
    "# z = z_mean + sqrt(var)*eps\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling fr an isotropic unit Gaussian.\n",
    "    # Arguments:\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "    # Returns:\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "image_shape = (28, 28, 1)\n",
    "original_dim = image_shape[0] * image_shape[1]\n",
    "input_shape = (original_dim,)\n",
    "num_classes = 36\n",
    "batch_size = 512\n",
    "latent_dim = 6\n",
    "epochs = 20\n",
    "beta = 1e-5\n",
    "name = \"CVAE_\" + str(beta)\n",
    "if not os.path.exists(\"./logs/\" + name):\n",
    "    os.makedirs(\"./logs/\" + name)\n",
    "\n",
    "tensorboard_callback = tensorboard_v2.TensorBoard(log_dir=\"./logs/\" + name)\n",
    "\n",
    "\n",
    "# encoder\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Reshape(image_shape)(inputs)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_cnn_encoder.png', show_shapes=True)\n",
    "\n",
    "# decoder\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "label_inputs = Input(shape=(num_classes,), name='label')\n",
    "x = Concatenate()([latent_inputs, label_inputs])\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(14 * 14 * 32, activation='relu')(x)\n",
    "x = Reshape((14, 14, 32))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "outputs = Reshape(input_shape)(x)\n",
    "\n",
    "decoder = Model([latent_inputs, label_inputs], outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='vae_cnn_decoder.png', show_shapes=True)\n",
    "\n",
    "# variational autoencoder\n",
    "outputs = decoder([encoder(inputs)[2], label_inputs])\n",
    "vae = Model([inputs, label_inputs], outputs, name='vae_mlp')\n",
    "vae.summary()\n",
    "plot_model(vae, to_file='vae_cnn.png', show_shapes=True)\n",
    "\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "# reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "kl_loss *= beta\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "import os\n",
    "\n",
    "# weights_file = 'vae_cnn_mnist1.h5'\n",
    "\n",
    "# if os.path.exists(weights_file):\n",
    "#     vae.load_weights(weights_file)\n",
    "#     print('Loaded weights!')\n",
    "# else:\n",
    "vae.fit([x_train, y_train],\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=([x_test, y_test], None),callbacks = [tensorboard_callback])\n",
    "vae.save(\"./logs/\" + name + \"/\" + name + \".hdf5\")\n",
    "#     vae.save_weights('vae_cnn_mnist.h5')\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "\n",
    "def show(im):\n",
    "    sns.heatmap(im.reshape((28, 28)), cmap='Greys', cbar=False, square=True, )\n",
    "\n",
    "sample = np.random.randint(len(x_test), size=10)\n",
    "reconst = vae.predict([x_test[sample], y_test[sample]])\n",
    "\n",
    "for i in range(10):\n",
    "    axes[0, i].get_xaxis().set_visible(False)\n",
    "    axes[0, i].get_yaxis().set_visible(False)\n",
    "    plt.sca(axes[0, i])\n",
    "    show(x_test[sample[i]])\n",
    "    axes[1, i].get_xaxis().set_visible(False)\n",
    "    axes[1, i].get_yaxis().set_visible(False)\n",
    "    plt.sca(axes[1, i])\n",
    "    show(reconst[i])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "def from_latent(num, vec):\n",
    "    vec = np.array(vec)\n",
    "    im = decoder.predict([vec.reshape(1, latent_dim), to_categorical([num], num_classes)]).reshape(28, 28)\n",
    "    return im\n",
    "\n",
    "@interact(num=(0, num_classes - 1),\n",
    "          x1=(-3., 3.), x2=(-3., 3.), x3=(-3., 3.),\n",
    "          x4=(-3., 3.), x5=(-3., 3.), x6=(-3., 3.))\n",
    "\n",
    "def f(num, x1, x2, x3, x4, x5, x6):\n",
    "    plt.figure(2)\n",
    "    plt.axis('off')\n",
    "    im = from_latent(num, [x1, x2, x3, x4, x5, x6])\n",
    "    sns.heatmap(im, square=True, cmap='Greys', cbar=False)\n",
    "    plt.show()\n",
    "\n",
    "def digit_image(digit, latent=None):\n",
    "    if latent is None:\n",
    "        latent = np.random.randn(latent_dim)\n",
    "    return from_latent(digit, latent)\n",
    "\n",
    "def number_image(num):\n",
    "    latent = 0.8 * np.random.randn(latent_dim)\n",
    "    width = 16\n",
    "    digits = str(num)\n",
    "    result = np.zeros((28, width * len(digits) + (28 - width)))\n",
    "    for i, d in enumerate(digits):\n",
    "        result[:, width*i:width*i + 28] += digit_image(int(d), latent + 0.5 * np.random.randn(latent_dim))\n",
    "    result = np.minimum(result, 1.0)\n",
    "    return result\n",
    "\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(number_image(314159))\n",
    "\n",
    "def sample_images(num, rows=10, cols=5):\n",
    "    images = []\n",
    "    for i in range(rows):\n",
    "        current = []\n",
    "        for j in range(cols):\n",
    "            current.append(number_image(num))\n",
    "        images.append(np.concatenate(current, axis=1))\n",
    "    return np.concatenate(images)\n",
    "\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(1 - sample_images(65537))\n",
    "plt.savefig('sample.png')\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "vae.load_weights(\"./logs/CVAE_50////CVAE_50.hdf5\")\n",
    "\n",
    "encoder = keras.Model(inputs = vae.get_layer(\"encoder\").inputs, outputs = vae.get_layer('encoder').outputs)\n",
    "\n",
    "out = encoder.predict(x_test)\n",
    "\n",
    "pd.DataFrame(out[1]).describe()\n",
    "\n",
    "import glob\n",
    "from sklearn.manifold import TSNE\n",
    "import natsort\n",
    "\n",
    "y_test\n",
    "\n",
    "sst = StratifiedKFold(n_splits=10)\n",
    "index = list(sst.split(x_test,np.argmax(y_test,axis = -1)))[0][-1]\n",
    "\n",
    "for file in glob.glob(\"./*/*/CVAE*hdf5\"):\n",
    "    plt.figure()\n",
    "    Beta = file.split(\"_\")[-1][:-5]\n",
    "    vae.load_weights(file)\n",
    "    encoder = keras.Model(inputs = vae.get_layer(\"encoder\").inputs, outputs = vae.get_layer('encoder').outputs)\n",
    "    out = encoder.predict(x_test[index])\n",
    "    x_emb = TSNE().fit_transform(out[0])\n",
    "    g = sns.scatterplot(x=x_emb[:,0],y = x_emb[:,1],hue=np.argmax(y_test[index],axis=-1),palette=sns.color_palette(\"Set2\", 36))\n",
    "    g.legend_.remove()\n",
    "    g.set_title(\"Beta =\" + str(Beta))\n",
    "\n",
    "vae.load_weights(file)\n",
    "encoder = keras.Model(inputs = vae.get_layer(\"encoder\").inputs, outputs = vae.get_layer('encoder').outputs)\n",
    "out = encoder.predict(x_test[index])    \n",
    "\n",
    "x_emb = TSNE().fit_transform(out[0])\n",
    "\n",
    "x_emb.shape\n",
    "\n",
    "sample = np.random.randint(len(x_test), size=10)\n",
    "\n",
    "fig, axes = plt.subplots(2, 10, figsize=(15, 3))\n",
    "\n",
    "def show(im):\n",
    "    sns.heatmap(im.reshape((28, 28)), cmap='Greys', cbar=False, square=True, )\n",
    "\n",
    "reconst = vae.predict([x_test[sample], y_test[sample]])\n",
    "\n",
    "for i in range(10):\n",
    "    axes[0, i].get_xaxis().set_visible(False)\n",
    "    axes[0, i].get_yaxis().set_visible(False)\n",
    "    plt.sca(axes[0, i])\n",
    "    show(x_test[sample[i]])\n",
    "    axes[1, i].get_xaxis().set_visible(False)\n",
    "    axes[1, i].get_yaxis().set_visible(False)\n",
    "    plt.sca(axes[1, i])\n",
    "    show(reconst[i])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
